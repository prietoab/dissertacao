\chapter{Resultados e discussão}
\label{cap:resultados}

%=========================================================	
\section{Problemas com o mínimo global}	
%=========================================================
	
	No capítulo \ref{sec:metodo} mostrei que o \textit{fitness} utilizado no artigo \cite{metodo2004}  foi
	
	\begin{equation}
		\label{eq:fitnessGrad2}
		f_i = e^{-\beta |\nabla \rho_i|^2},
	\end{equation}
	onde $f_i$ é o \textit{fitness} do $i$-ésimo indivíduo da população, $\beta$ é um parâmetro para evitar o estouro do \textit{fitness} e $| \nabla \rho_i|^2$ é o módulo ao quadrado do vetor gradiente de $\rho$, dado por
		
				\begin{equation}
					\nabla \rho_i = \frac{2[H - \rho_i]C_i}{C_i^t C_i},
				\end{equation}
	em que $C_i$ é um vetor candidato à solução do problema do autovalor
	
	\begin{equation}
		HC = EC.
	\end{equation}
	
	Além disso, se $C_i$ é de fato um dos autovetores, $\rho$ é o autovalor associado $E_i$:
	
	\begin{equation}\label{eq:rho_eh_E}
		\rho_i = \frac{C_i^t H C_i}{C_i^t C_i} = E_i.
	\end{equation}
	
	A fim de reproduzir os resultados, testei o método com matrizes de Coope$-$Sabo (equação \ref{eq:MatrizCoope}) de ordem 10, 20, 30 e 40, utilizando os mesmos parâmetros encontrados em \cite{metodo2004}: probabilidade de \textit{crossover} $p_c = 75\%$, probabilidade de mutação $p_m = 50\%$ e intensidade de mutação $\Delta = 0,01$. Com um bom ajuste de $\beta$, que será discutido em detalhes posteriormente, o \textit{fitness} comportou-se conforme o esperado em todos os casos. Um exemplo está na figura \ref{fig:compFitnessTipo1N10}, que apresenta o melhor fitness de cada geração para uma matriz de ordem N = 10. Na primeira geração o melhor \textit{fitness} é pequeno, aproximadamente 0,1, cresce rapidamente e a partir da décima geração está próximo de 1.
	
	\begin{figure}[htbp]
		\centering
			\includegraphics{figs/resultados/fitnessGrad/N10_00_fitness.pdf}
			\caption{Comportamento do \textsl{fitness} $f_i = e^{-\beta |\nabla \rho_i|^2}$ para N = 10. Na primeira geração o melhor \textit{fitness} é pequeno, aproximadamente 0,1, cresce rapidamente e a partir da décima geração está próximo de 1.}
		\label{fig:compFitnessTipo1N10}
	\end{figure}
	
	O passo seguinte foi verificar o comportamento de $\rho$, o Quociente de Rayleigh, e, especificamente, sua convergência para o menor autovalor $E_0$. Ainda conforme \cite{metodo2004}, obteríamos uma curva semelhante à da figura \ref{fig:compFitnessTipo1N10}, mas invertida, ou seja, os primeiros valores de $\rho$ seriam grandes e, rapidamente, diminuiriam até haver convergência para o autovalor mínimo. Na figura \ref{fig:rho_N10} há um exemplo.	Os gráficos exibem os valores de $\rho$ para a mesma execução apresentada na figura \ref{fig:compFitnessTipo1N10}. Note no primeiro gráfico que até a geração 20 o quociente $\rho$ teve caráter oscilatório e, então, aparentemente estabilizou-se entre 6 e 8, valores muito superiores ao autovalor mínimo para essa matriz, $E_0 = 0,38675$. Entretanto, ainda no primeiro gráfico, observa-se que há uma tendência de queda do $\rho$ entre as gerações 40 e 50 e, portanto, existiria a possibilidade de o algoritmo convergir para $E_0$. Porém, para esse exemplo especificamente, isso não aconteceu, como pode ser visto no segundo gráfico da figura \ref{fig:rho_N10}. Para garantir a estabilidade, o programa foi executado até a geração 400.000, e o valor médio obtido foi $<\rho> = 6,572898$. Para minha surpresa, além do valor obtido de $<\rho>$ não ser o mínimo, ele não é um valor qualquer, mas corresponde, com erro\footnote{Nesse contexto, quando comparo os resultados do meu programa com os do Scilab, a palavra \emph{erro} é equivalente à palavra \emph{distância}. Para matrizes com ordem superior a quatro é impossível encontrar soluções exatas para os autovalores e, portanto, os valores obtidos no Scilab também são aproximações. No entanto, assumi que as aproximações do Scilab são muito boas e, por isso, usei--o como padrão. Então, pequenas distâncias entre os valores do meu programa e os do Scilab indicam que o erro do meu \emph{software} também é pequeno.} menor que $0,00002\%$, ao quarto autovalor da matriz, $E_3 = 6,572897$. Imaginei, então, que poderia haver algo de errado com o programa. 
	
	\begin{figure}[htbp]
		\centering
			\includegraphics[width=0.48\textwidth]{figs/resultados/rho_N10_g50.pdf}
			\includegraphics[width=0.48\textwidth]{figs/resultados/rho_N10_g400000.pdf}
		\caption{Comportamento de $\rho$ (Quociente de Rayleigh) para uma matriz de Coope$-$Sabo de ordem 10.}
		\label{fig:rho_N10}
	\end{figure}
	
	\newpage
	
	Após esses resultados preliminares executei uma validação cuidadosa do programa, testando cada uma de suas quase 2500 linhas e comparando os resultados das operações e cálculos com o Microsoft Excel e SciLab. A hipótese era a de que erros numéricos, principalmente nas funções de álgebra linear e nos operadores genéticos, pudessem ter levado ao comportamento incorreto da não convergência para o menor autovalor. Nenhum erro significativo foi encontrado.
	
	Os testes com a versão corrigida do programa estão nas figuras \ref{fig:execucoes_N10}, \ref{fig:execucoes_N20}, \ref{fig:execucoes_N30} e \ref{fig:execucoes_N40}. Visando brevidade, apresentarei dados para matrizes de Coope$-$Sabo de ordem 10, 20, 30 e 40 apenas, sem perda de generalidade. Foram cinco execuções para cada matriz, até a geração 400.000, gerando sempre dois gráficos, um do \textit{fitness} médio (<\textit{fitness}>) e outro do Quociente de Rayleigh médio (<$\rho$>), ambos em função do número de gerações, e dando ênfase às primeiras 100 gerações. Essas escolhas, número máximo da geração e uso de médias sobre cada população, visaram garantir, respectivamente, a convergência genética e boa precisão. A exibição de apenas as primeiras 100 gerações tem como objetivo olhar em detalhe (com \textit{zoom}) o período em que o \textit{crossover} tem mais peso, ou seja, onde há geralmente os saltos no espaço de soluções de um Algoritmo Genético. Em todos os gráficos de $<\rho>$ há indicado nas legendas o autovalor mínimo $E_0$ e o autovalor obtido após as 400.000 gerações ($E_{obtido}$). Na tabela \ref{tab:autovalores10a40} há a lista de todos os autovalores. Por exemplo, para uma matriz de ordem $N = 10$, o menor autovalor é $E_0 = $0,386075, e o quinto autovalor para $N = 30$ é $E_4$ = 8,450274.

\begin{table}[htb]
	\caption{Lista de autovalores para matrizes de Coope$-$Sabo de ordem 10, 20, 30 e 40.}
	\label{tab:autovalores10a40}
% Table generated by Excel2LaTeX from sheet 'Todos'
\begin{center}
\begin{tabular}{r|r|r|r|r}
	\hline \hline
	\textbf{\#} &   \textbf{10} &   \textbf{20} &   \textbf{30} &   \textbf{40} \\
	\hline \hline
					 0 &   0,386075 &   0,341237 &   0,319737 &   0,306086 \\
	\hline
					 1 &   2,461056 &   2,397247 &    2,36844 &   2,350583 \\
	\hline
					 2 &   4,518931 &   4,436173 &   4,401134 &   4,379909 \\
	\hline
					 3 &   6,572897 &   6,468521 &   6,427419 &     6,4031 \\
	\hline
					 4 &   8,628524 &   8,497626 &   8,450274 &    8,42294 \\
	\hline
					 5 &   10,69057 &   10,52507 &   10,47105 &   10,44068 \\
	\hline
					 6 &   12,76574 &   12,55178 &    12,4905 &     12,457 \\
	\hline
					 7 &   14,86753 &   14,57845 &   14,50908 &   14,47232 \\
	\hline
					 8 &   17,03654 &   16,60562 &   16,52713 &   16,48692 \\
	\hline
					9 &   22,07215 &   18,63385 &   18,54488 &     18,501 \\
	\hline
					10 &            &    20,6637 &   20,56255 &    20,5147 \\
	\hline
					11 &            &   22,69588 &    22,5803 &   22,52816 \\
	\hline
					12 &            &   24,73127 &   24,59828 &   24,54146 \\
	\hline
					13 &            &   26,77114 &   26,61667 &   26,55469 \\
	\hline
					14 &            &   28,81733 &    28,6356 &   28,56792 \\
	\hline
					15 &            &   30,87288 &   30,65527 &   30,58122 \\
	\hline
					16 &            &   32,94325 &   32,67586 &   32,59466 \\
	\hline
					17 &            &   35,04014 &    34,6976 &   34,60831 \\
	\hline
					18 &            &   37,19805 &   36,72077 &   36,62223 \\
	\hline
					19 &            &    45,2308 &   38,74571 &   38,63648 \\
	\hline
					20 &            &            &   40,77285 &   40,65114 \\
	\hline
					21 &            &            &   42,80277 &    42,6663 \\
	\hline
					22 &            &            &   44,83625 &   44,68204 \\
	\hline
					23 &            &            &   46,87444 &   46,69846 \\
	\hline
					24 &            &            &   48,91902 &   48,71568 \\
	\hline
					25 &            &            &   50,97274 &   50,73385 \\
	\hline
					26 &            &            &   53,04052 &   52,75311 \\
	\hline
					27 &            &            &   55,13271 &   54,77369 \\
	\hline
					28 &            &            &   57,27946 &   56,79581 \\
	\hline
					29 &            &            &   68,37101 &   58,81981 \\
	\hline
					30 &            &            &            &   60,84608 \\
	\hline
					31 &            &            &            &   62,87517 \\
	\hline
					32 &            &            &            &   64,90781 \\
	\hline
					33 &            &            &            &   66,94504 \\
	\hline
					34 &            &            &            &   68,98845 \\
	\hline
					35 &            &            &            &   71,04053 \\
	\hline
					36 &            &            &            &   73,10578 \\
	\hline
					37 &            &            &            &   75,19353 \\
	\hline
					38 &            &            &            &   77,33102 \\
	\hline
					39 &            &            &            &   91,50634 \\
	\hline \hline
	\end{tabular}
	\end{center}  
\end{table}
	
	Há características comuns encontradas em todas as execuções. Em qualquer gráfico do \textit{fitness} observa-se estabilidade do comportamento conforme esperado pelo método: no início seu valor é baixo, próximo de zero, cresce rapidamente nas primeiras gerações e fica estável próximo de $<fitness> = 1$. Com relação ao $\rho$, há sempre oscilações, sejam pequenas variações em torno de uma clara linha de tendência, como na execução 02 para N = 10, ou grandes saltos, como nas execuções 05 de N = 20 e 05 de N = 30. Novamente, o menor autovalor não foi obtido em nenhuma execução, contradizendo os resultados de \cite{metodo2004}, mas, por outro lado, o algoritmo sempre encontrou algum autovalor.
	
	De fato, verificando os dados da tabela \ref{tab:execucoes10a40}, concluí que tais valores não devem ser coincidência. Para todas as execuções o \textit{fitness} médio chegou ao valor máximo \mbox{($<f> = 1,000000$)}. As médias de $\rho$ sobre todos os indivíduos da última população possuem baixo desvio padrão ($\sigma$ < 0,0001), indicando que eles são muito parecidos entre si e que o algoritmo convergiu. Ou seja, não há variabilidade genética suficiente na população para alterar o rumo da busca de modo a atingir o menor autovalor, ou o mínimo global. Portanto, o algoritmo chegou em um mínimo local, corroborado pelos baixos erros relativos de $<\rho>$ quando comparado com o autovalor mais próximo. Por exemplo, para N = 30, execução 4,  $<\rho>$ = 40,772447, correspondendo, com erro relativo absoluto menor que $0,001\%$, ao vigésimo primeiro autovalor, $E_{20} = 40,772850$. Apesar das evidências descritas acima, até esse ponto ainda havia dúvidas sobre a validade do programa e, obviamente, dos resultados produzidos. Então, busquei embasamento mais rigoroso.

De acordo com \cite{metodo2004}, se algum $C_i$, em algum momento, é o autovetor fundamental (associado ao menor autovalor), o $\nabla \rho$ é nulo. Com o \textit{fitness} da equação \eqref{eq:fitnessGrad2} os autores afirmam que ``\textit{Claramente, $f_i \rightarrow 1$ quando $\nabla \rho_i \rightarrow 0$, sinalizando que a evolução atingiu o verdadeiro autovetor fundamental de $H$ em $C_i$}''\footnote{Tradução livre de ``\textit{Clearly, $f_i \rightarrow 1$, as $\nabla \rho_i \rightarrow 0$, signalling that the evolution has hit the true ground state eigenvector of $H$ in the vector $C_i$}''.}. Há duas relações distintas de causalidade nessa frase, e acredito que nelas residam a explicação dos resultados obtidos até agora.

A primeira relação de causalidade refere-se à afirmação ``\textit{$f_i \rightarrow 1$ quando $\nabla \rho_i \rightarrow \textbf{0}$}'', que está absolutamente correta. Retomando a seção \ref{sec:fitness_metodo}, o \textit{fitness} definido pela equação \ref{eq:fitnessGrad2} é limitado ao intervalo (0,1] e, como $\beta > 0$, só chega ao seu valor máximo quando $\nabla \rho_i = \textbf{0}$. Em outras palavras, $\nabla \rho_i \rightarrow \textbf{0}$ implica $f_i \rightarrow 1$.

Na afirmação ``(...) \textit{sinalizando que a evolução atingiu o verdadeiro autovetor fundamental de $H$ em $C_i$}'' reside a segunda relação de causalidade:

\begin{equation}\label{eq:afirmacaoErrada}
	\mbox{Se } f_i \rightarrow 1\mbox{, } C_i = C_0.
\end{equation}

Ou seja, sempre que algum indivíduo $C_i$, de qualquer população, possuir \textit{fitness} muito próximo de 1, isso implica que, além de ter uma excelente ``nota'', ele também é um vetor especial, o autovetor fundamental $C_0$. Portanto, possui autovalor associado $E_0$, o autovalor mínimo (conforme equação \ref{eq:rho_eh_E}). Grosso modo, $f_i(C_i) = 1$ implica que $C_i = C_0$ e que podemos obter $E_0(C_0)$:

\begin{equation}\label{eq:causalidadeErrada}
	f_i(C_i) = 1 \rightarrow C_i = C_0 \rightarrow E_0(C_0).
\end{equation}

As relações de causa e efeito da equação acima estão erradas. Em sua obra clássica sobre o problema de autovalores em matrizes simétricas, \cite{Parlett1998} abre o capítulo introdutório frisando que ``\textit{em muitos lugares no livro, é feita referência a fatos mais ou menos bem conhecidos sobre a teoria de matrizes}''. Conforme já dito no capítulo \ref{cap:algebra}, um desses fatos diz que $\rho(\mbox{\textit{u}})$ é estacionário, ou seja, $\nabla \rho(\mbox{\textit{u}}) = \textbf{0}$, apenas se o vetor \textit{u} é um autovetor $w$ de $HC = EC$. Consequentemente, o encadeamento correto se apresenta como:

\begin{equation}\label{eq:causalidadeCorreta}
	C_i \mbox{ é um autovetor} \rightarrow \nabla \rho(C_i) = \textbf{0} \rightarrow f_i = 1.
\end{equation}
	
Então, se $f_i = 1$, o máximo que podemos concluir é que $C_i$ é \textit{algum} autovetor, e não necessariamente \textit{o} autovetor fundamental.

Acredito que o programa não contém erros. Ao final de todos os testes o \textit{fitness} médio foi <\textit{f}> = 1, a população final era composta por autovetores e foi possível, com boa precisão, obter os autovalores relacionados (não necessariamente o autovalor mínimo). Os dados, portanto, confirmaram a matemática.

Apesar de não chegar ao mínimo, o método pode ser utilizado de maneira exploratória com relativa facilidade, bastando extrair $\rho$ sempre que $f_i \rightarrow 1$ e $\nabla \rho \rightarrow \textbf{0}$. 

Resta a dúvida: afinal, como o autovalor mínimo foi obtido com o \textit{fitness} definido pela equação \ref{eq:fitnessGrad2}? Não sei. Esse \textit{fitness} foi utilizado não só em \cite{metodo2004}, mas também em \cite{metodo2006}, \cite{metodo2008} e \cite{metodo2009}, seguindo exatamente o argumento resumido pela equação \ref{eq:causalidadeErrada}. Não identifiquei nada nesses quatro artigos que pudesse levar à resposta. Segui o estudo com uma nova definição do \textit{fitness} encontrada em \cite{metodo2011}.

\newpage
\begin{figure}[p]
\centering
  \begin{tabular}{@{}cc@{}}
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N10_01_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N10_01_rho.pdf}   \\
		\includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N10_02_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N10_02_rho.pdf}   \\
		\includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N10_03_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N10_03_rho.pdf}   \\
		\includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N10_04_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N10_04_rho.pdf}   \\
		\includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N10_05_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N10_05_rho.pdf}
    %\multicolumn{2}{c}{\includegraphics[width=.23\textwidth]{example-image-a}}
  \end{tabular}
  \caption{Execuções N = 10.}
	\label{fig:execucoes_N10}
\end{figure}

\newpage
\begin{figure}[p]
\centering
  \begin{tabular}{@{}cc@{}}
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N20_01_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N20_01_rho.pdf}   \\
		\includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N20_02_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N20_02_rho.pdf}   \\
		\includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N20_03_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N20_03_rho.pdf}   \\
		\includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N20_04_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N20_04_rho.pdf}   \\
		\includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N20_05_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N20_05_rho.pdf}
    %\multicolumn{2}{c}{\includegraphics[width=.23\textwidth]{example-image-a}}
  \end{tabular}
  \caption{Execuções N = 20.}
	\label{fig:execucoes_N20}
\end{figure}

\newpage
\begin{figure}[p]
\centering
  \begin{tabular}{@{}cc@{}}
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N30_01_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N30_01_rho.pdf}   \\
		\includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N30_02_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N30_02_rho.pdf}   \\
		\includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N30_03_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N30_03_rho.pdf}   \\
		\includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N30_04_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N30_04_rho.pdf}   \\
		\includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N30_05_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N30_05_rho.pdf}
    %\multicolumn{2}{c}{\includegraphics[width=.23\textwidth]{example-image-a}}
  \end{tabular}
  \caption{Execuções N = 30.}
	\label{fig:execucoes_N30}
\end{figure}

\newpage
\begin{figure}[p]
\centering
  \begin{tabular}{@{}cc@{}}
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N40_01_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N40_01_rho.pdf}   \\
		\includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N40_02_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N40_02_rho.pdf}   \\
		\includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N40_03_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N40_03_rho.pdf}   \\
		\includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N40_04_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N40_04_rho.pdf}   \\
		\includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N40_05_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/fitnessGrad/N40_05_rho.pdf}
    %\multicolumn{2}{c}{\includegraphics[width=.23\textwidth]{example-image-a}}
  \end{tabular}
  \caption{Execuções N = 40.}
	\label{fig:execucoes_N40}
\end{figure}


\newpage
\begin{landscape}
\begin{center}
\begin{table}[htbp]
\caption{Execuções para matrizes de Coope$-$Sabo.}
\label{tab:execucoes10a40}
% Table generated by Excel2LaTeX from sheet 'Plan1 (2)'
\begin{tabular}{cccccccccc}
\hline \hline
   \textbf{N} & \textbf{Execução} & \textbf{Semente} & \textbf{$\beta$} & \textbf{<\textit{Fitness}>} & \textbf{<$\rho$>} & \textbf{$\sigma$} & \textbf{\# autovalor} & \textbf{Autovalor} & \textbf{Erro relativo} \\
\hline \hline
        10 &          0 & 1445738835 &   0,128788 &   1,000000 &   2,461122 &   0,000023 &          1 &   2,461056 &    0,003\% \\
\hline
        10 &          1 & 1445780626 &   0,128788 &   1,000000 &   6,572898 &   0,000013 &          3 &   6,572897 &  0,00001\% \\
\hline
        10 &          2 & 1445780762 &   0,128788 &   1,000000 &   6,572883 &   0,000015 &          3 &   6,572897 &  -0,0002\% \\
\hline
        10 &          3 & 1445780907 &   0,128788 &   1,000000 &   6,572910 &   0,000016 &          3 &   6,572897 &   0,0002\% \\
\hline
        10 &          4 & 1445781049 &   0,128788 &   1,000000 &  12,765701 &   0,000016 &          6 &  12,765740 &  -0,0003\% \\
\hline
        10 &          5 & 1445781195 &   0,128788 &   1,000000 &   4,518952 &   0,000012 &          2 &   4,518931 &   0,0005\% \\
\hline
        20 &          1 & 1445795292 &   0,026665 &   1,000000 &   8,498192 &   0,000052 &          4 &   8,497626 &    0,007\% \\
\hline
        20 &          2 & 1445795501 &   0,026665 &   1,000000 &  12,551830 &   0,000018 &          6 &  12,551780 &   0,0004\% \\
\hline
        20 &          3 & 1445795718 &   0,026665 &   1,000000 &  12,551878 &   0,000020 &          6 &  12,551780 &   0,0008\% \\
\hline
        20 &          4 & 1445795953 &   0,026665 &   1,000000 &  14,578527 &   0,000035 &          7 &  14,578450 &   0,0005\% \\
\hline
        20 &          5 & 1445796166 &   0,026665 &   1,000000 &  18,634220 &   0,000062 &          9 &  18,633850 &    0,002\% \\
\hline
        30 &          1 & 1445796378 &   0,011171 &   1,000000 &  26,616790 &   0,000065 &         13 &  26,616670 &   0,0005\% \\
\hline
        30 &          2 & 1445796746 &   0,011171 &   1,000000 &  26,616595 &   0,000029 &         13 &  26,616670 &  -0,0003\% \\
\hline
        30 &          3 & 1445797109 &   0,011171 &   1,000000 &  22,580060 &   0,000051 &         11 &  22,580300 &   -0,001\% \\
\hline
        30 &          4 & 1445797473 &   0,011171 &   1,000000 &  40,772447 &   0,000071 &         20 &  40,772850 &   -0,001\% \\
\hline
        30 &          5 & 1445797882 &   0,011171 &   1,000000 &  30,655283 &   0,000022 &         15 &  30,655270 &  0,00004\% \\
\hline
        40 &          1 & 1445798248 &   0,006105 &   1,000000 &  26,554758 &   0,000040 &         13 &  26,554690 &   0,0003\% \\
\hline
        40 &          2 & 1445798838 &   0,006105 &   1,000000 &  54,773734 &   0,000078 &         27 &  54,773690 &  0,00008\% \\
\hline
        40 &          3 & 1445799429 &   0,006105 &   1,000000 &  58,819413 &   0,000087 &         29 &  58,819810 &  -0,0007\% \\
\hline
        40 &          4 & 1445800091 &   0,006105 &   1,000000 &  40,651473 &   0,000077 &         20 &  40,651140 &   0,0008\% \\
\hline
        40 &          5 & 1445800683 &   0,006105 &   1,000000 &  40,650764 &   0,000061 &         20 &  40,651140 &  -0,0009\% \\
\hline \hline
\end{tabular}
\end{table}  
\end{center}
\end{landscape}

%=========================================================
\newpage
\section{Outro \textit{fitness} para encontrar o mínimo global}
%=========================================================

	O novo \emph{fitness}, apresentado em \cite{metodo2011}, é dado por
	
	\begin{equation}\label{eq:fitnessRho0}
		f_i = e^{-\beta(\rho_i - E_L)^2},
	\end{equation}
e contém semelhanças com o definido pela equação \ref{eq:fitnessGrad2}. Há uso de uma exponencial, o parâmetro $\beta$ foi mantido e possui exatamente o mesmo papel, $f_i$ depende apenas de $\rho$ e, como $(\rho_i - E_L)^2$ é claramente positivo, o \textit{fitness} continua limitado ao conjunto (0,1]. As diferenças estão na ausência do $\nabla \rho$ e na inclusão do parâmetro $E_L$, que representa um limite inferior para o \textit{menor} autovalor\footnote{L de \textit{lower}.}. Por exemplo, se soubermos de antemão que o autovalor \textit{mínimo} é maior que zero, poderíamos definir $E_L = 0$. 

	 A justificativa para o funcionamento do método em \cite{metodo2011} segue a mesma estrutura de \cite{metodo2004}: ``\textit{Se $\rho_i \rightarrow E_L$ durante a busca, $f_i \rightarrow 1$ e $C_i$ está próximo do autovetor fundamental de $H$}''\footnote{Tradução livre de ``\textit{If $\rho_i \rightarrow E_L$ during the search, $f_i \rightarrow 1$ and $C_i$ approaches the ground eigenvector of $H$}''.}. Parece que, novamente, não há garantia de que, se $f_i \rightarrow 1$, $\rho$ tende, necessariamente, ao autovalor fundamental. E aqui há um agravante: nada na equação \ref{eq:fitnessRho0} está diretamente associado aos autovalores de $H$. Lembre que o \textit{fitness} anterior (equação \ref{eq:fitnessGrad2}) contém $\nabla \rho$, que possui relação direta com os autovalores de $H$ quando $\nabla \rho = \textbf{0}$.
	
	O autovalor mínimo foi encontrado, mas a qualidade foi inferior. Repeti as execuções da tabela \ref{tab:execucoes10a40} alterando apenas o \textit{fitness} e configurando o parâmetro $E_L$ para $E_L = 0$, um pouco abaixo dos autovalores mínimos. Os resultados estão na página \pageref{tab:execucoesNovoFitness}, e os gráficos da evolução do \textit{fitness} e do quociente de Rayleigh estão nas páginas \pageref{fig:execucoes_N10_EL}, \pageref{fig:execucoes_N20_EL}, \pageref{fig:execucoes_N30_EL} e \pageref{fig:execucoes_N40_EL}. Surpreendentemente, apesar do que foi dito no parágrafo anterior, o programa encontrou o menor autovalor em \textbf{todos} os casos. Assim como nas primeiras execuções, o desvio padrão ($\sigma$) de $<\rho>$ na última geração (400.000) foi pequeno, indicando convergência genética. Entretanto, essa foi a única semelhança. Os próprios valores de $\sigma$ são uma ordem de grandeza menores, sugerindo que os indivíduos são mais semelhantes entre si. O \textit{fitness} médio só atingiu seu valor máximo para a matriz de ordem $N = 40$. Aliás, especificamente para $E_L$ fixado em $E_L = 0$, o <\textit{fitness}> final diminui com $N$, pois $E_L$ está mais distante de $E_0$ na matriz de ordem 10 do que na de ordem 40. Os erros relativos não ultrapassaram $1\%$, mas foram substancialmente maiores comparados aos obtidos com o primeiro \textit{fitness}. Enquanto nos testes anteriores seus valores permaneceram estáveis, agora os erros relativos apresentaram tendência de crescimento com N.
	
	\begin{landscape}
\begin{center}
\begin{table}[htbp]
\caption{Execuções novo \textit{Fitness}.}
\label{tab:execucoesNovoFitness}
	% Table generated by Excel2LaTeX from sheet 'Tabela LaTex'
\begin{tabular}{cccccccccc}
\hline \hline
   \textbf{N} & \textbf{Execução} & \textbf{Semente} & \textbf{$\beta$} & \textbf{<Fitness>} & \textbf{<$\rho$>} & \textbf{$\sigma$} & \textbf{\# autovalor} & \textbf{Autovalor} & \textbf{Erro relativo (\%)} \\
\hline \hline
        10 &          0 & 1445738835 &   0,128788 &   0,999044 &   0,386176 &    0,00005 &          0 &  0,3860745 &     0,03\% \\
\hline
        10 &          1 & 1445780626 &   0,128788 &   0,999044 &   0,386169 &    0,00003 &          0 &  0,3860745 &     0,02\% \\
\hline
        10 &          2 & 1445780762 &   0,128788 &   0,999045 &   0,386132 &    0,00002 &          0 &  0,3860745 &     0,01\% \\
\hline
        10 &          3 & 1445780907 &   0,128788 &   0,999044 &   0,386175 &    0,00005 &          0 &  0,3860745 &     0,03\% \\
\hline
        10 &          4 & 1445781049 &   0,128788 &   0,999043 &   0,386211 &    0,00003 &          0 &  0,3860745 &     0,04\% \\
\hline
        10 &          5 & 1445781195 &   0,128788 &   0,999044 &   0,386183 &    0,00005 &          0 &  0,3860745 &     0,03\% \\
\hline
        20 &          1 & 1445795292 &   0,026665 &   0,999954 &   0,341484 &    0,00005 &          0 &  0,3412367 &     0,07\% \\
\hline
        20 &          2 & 1445795501 &   0,026665 &   0,999954 &   0,341693 &     0,0001 &          0 &  0,3412367 &      0,1\% \\
\hline
        20 &          3 & 1445795718 &   0,026665 &   0,999954 &    0,34147 &    0,00006 &          0 &  0,3412367 &     0,07\% \\
\hline
        20 &          4 & 1445795953 &   0,026665 &   0,999954 &   0,341689 &     0,0001 &          0 &  0,3412367 &      0,1\% \\
\hline
        20 &          5 & 1445796166 &   0,026665 &   0,999954 &    0,34153 &    0,00007 &          0 &  0,3412367 &     0,09\% \\
\hline
        30 &          1 & 1445796378 &   0,011171 &   0,999995 &   0,320582 &     0,0001 &          0 &   0,319737 &      0,3\% \\
\hline
        30 &          2 & 1445796746 &   0,011171 &   0,999995 &   0,320772 &     0,0002 &          0 &   0,319737 &      0,3\% \\
\hline
        30 &          3 & 1445797109 &   0,011171 &   0,999995 &   0,320699 &     0,0001 &          0 &   0,319737 &      0,3\% \\
\hline
        30 &          4 & 1445797473 &   0,011171 &   0,999995 &   0,320755 &     0,0001 &          0 &   0,319737 &      0,3\% \\
\hline
        30 &          5 & 1445797882 &   0,011171 &   0,999995 &   0,320274 &    0,00007 &          0 &   0,319737 &      0,2\% \\
\hline
        40 &          1 & 1445798248 &   0,006105 &          1 &   0,306968 &     0,0001 &          0 &   0,306086 &      0,3\% \\
\hline
        40 &          2 & 1445798838 &   0,006105 &          1 &   0,307128 &     0,0001 &          0 &   0,306086 &      0,3\% \\
\hline
        40 &          3 & 1445799429 &   0,006105 &          1 &   0,307297 &     0,0002 &          0 &   0,306086 &      0,4\% \\
\hline
        40 &          4 & 1445800091 &   0,006105 &          1 &   0,307816 &     0,0002 &          0 &   0,306086 &      0,6\% \\
\hline
        40 &          5 & 1445800683 &   0,006105 &          1 &    0,30765 &     0,0002 &          0 &   0,306086 &      0,5\% \\

\hline \hline
\end{tabular}
\end{table}  
\end{center}
\end{landscape}
	
	Apesar das diferenças dos valores finais, o comportamento do \textit{fitness} e do $\rho$ ao longo da busca não foi alterado significativamente. Na figura \ref{fig:N-10_E-0_fitness} estão os gráficos referentes à execução zero para o Hamiltoniano de ordem 10, semente 1445738835. A primeira usa o \textit{fitness} $f_i = e^{-\beta(\rho_i - E_L)^2}$, que chega ao autovalor mínimo, enquanto a segunda utiliza o $f_i = e^{-\beta | \nabla \rho_i |^2}$. Ambos iniciam com valores muito baixos e convergem para 1, entretanto, o da esquerda é muito ruidoso e, aparentemente, essa é a causa da convergência mais lenta. Quando a curva da direita já está estável em $\textit{<f>} \approx 1$ em torno da geração de número 15, a da esquerda ainda não ultrapassou o $\textit{<f>} = 0,1$. A princípio, não podemos comparar os dois comportamentos diretamente, visto que cada um chegou a um autovalor diferente. A execução da direita, lembre-se, obteve apenas um mínimo local ($E_1 = 2,461056$, tabela \ref{tab:execucoes10a40}).
	
	\begin{figure}[htbp]
		\centering
			\includegraphics[width=0.48\textwidth]{figs/resultados/fitnessEL/N-10_E-0_fitness.pdf}
			\includegraphics[width=0.48\textwidth]{figs/resultados/fitnessGrad/N10_00_fitness.pdf}
		\caption{Comportamento do \textit{fitness} para as execuções zero do Hamiltoniano de ordem 10, semente 1445738835. A primeira usa o \textit{fitness} $f_i = e^{-\beta(\rho_i - E_L)^2}$, que chega ao autovalor mínimo, enquanto a segunda utiliza o $f_i = e^{-\beta \| \nabla \rho_i \|^2}$.}
		\label{fig:N-10_E-0_fitness}
	\end{figure}
	
	De todo modo, as duas execuções estão conectadas pois, como partiram da mesma semente de números pseudoaleatórios, a população inicial foi a mesma. Inclusive, na primeira geração, em ambas as execuções, os valores para $<\rho>$ e para o melhor $\rho$ foram, respectivamente, $9,876075$ e $9,557892$, igualmente distantes do autovalor mínimo $E_0 = 0,386075$. Os gráficos da figura \ref{fig:N-10_E-0_rho_comparacao} permitem comparar a evolução do $<\rho>$ nos dois casos. Assim como na figura anterior, a imagem da esquerda refere-se ao uso do \textit{fitness} $f_i = e^{-\beta(\rho_i - E_L)^2}$.
	
	Alguém poderia afirmar que a causa de uma execução ter sido mais lenta do que a outra foi porque percorreu um caminho mais longo ao sair de $<\rho> = 9,876075$, passar por $E_1 = 2,461056$ e continuar até encontrar $E_0 = 0,386075$, enquanto a mais rápida saiu do mesmo $<\rho>$ e parou logo que encontrou $E_1$. Infelizmente essa conclusão estaria incorreta. A maneira que se percorre o espaço de soluções com os GAs tem base estocástica e, portanto, qualquer comparação linear é extremamente arriscada, quiçá impossível. Objetivamente, posso apenas concluir que os valores finais encontrados por cada \textit{fitness} condizem com a construção de cada função objetivo: $\nabla \rho_i$ leva a qualquer autovalor; $\rho_i - E_L$, com $E_L$ configurado apropriadamente, encontra o autovalor mínimo.
	
	
	\begin{figure}[htbp]
		\centering
			\includegraphics[width=0.48\textwidth]{figs/resultados/fitnessEL/N-10_E-0_rho.pdf}
			\includegraphics[width=0.48\textwidth]{figs/resultados/fitnessGrad/N10_00_rho.pdf}
		\caption{Comportamento do $\rho$ para as execuções zero do Hamiltoniano de ordem 10, semente 1445738835. A primeira usa o \textit{fitness} $f_i = e^{-\beta(\rho_i - E_L)^2}$, que chega ao autovalor mínimo, enquanto a segunda utiliza o $f_i = e^{-\beta \| \nabla \rho_i \|^2}$.}
		\label{fig:N-10_E-0_rho_comparacao}
	\end{figure}	
	
	O limite inferior $E_L$ é o responsável pelo funcionamento do \emph{fitness} (equação \ref{eq:fitnessRho0}), pois o termo $(\rho_i - E_L)$ minimiza diretamente $\rho$. Se $(\rho_i - E_L)$ é grande, $f_i$ é pequeno, e isso significa que o vetor $C_i$ associado a $\rho_i$ está distante do autovetor fundamental $C_0$. Portanto, indivíduos com $(\rho_i - E_L)$ menores (e \emph{fitness} maiores) serão selecionados mais vezes. De acordo com a equação \ref{eq:autovalores_ordenados}, o processo fica estável quando é impossível diminuir $\rho_i$, ou seja, quando $<\rho> \rightarrow E_0$. 

	À primeira vista, esse \emph{fitness} não parece útil. Os valores finais do \emph{fitness} só foram próximos de 1 porque escolhi $E_L$ próximo de $E_0$. Ou seja, eu tinha conhecimento prévio do menor autovalor. Se o objetivo é encontrar $E_0$ e eu não tenho conhecimento sobre a região onde ele se encontra, como escolher apropriadamente $E_L$? Os autores de \cite{metodo2011} não falam nada a respeito.
	
	Então, para a mesma semente 1445738835, $\beta = 0,128788$ e $N = 10$, cujo $E_0 = 0,386075$, testei quatro cenários. O objetivo foi verificar em quais condições o autovalor mínimo é encontrado. O resumo dos resultados está na tabela \ref{tab:VariandoELPraPrimeiraExecucao}.
	
	\begin{itemize}
	
		\item \textbf{Cenário 1}: $E_L$ um pouco acima de $E_0$.
			
		\item \textbf{Cenário 2}: $E_L$ um pouco abaixo do $E_0$.
		
		\item \textbf{Cenário 3}: $E_L$ muito acima de $E_0$.
		
		\item \textbf{Cenário 4}: $E_L$ muito abaixo de $E_0$.
	\end{itemize}
	
	
	Não há surpresa no \textbf{Cenário 2}. Como citado no início desta seção, a escolha de $E_L$ um pouco abaixo de $E_0$ garante o mínimo global. Nos testes obtive o menor autovalor em todas as execuções, com \emph{fitness} médio próximo de 1 e $<|\nabla \rho|>$ próximo de zero. Portanto, o \textbf{Cenário 2} é o melhor cenário possível.	
	
	Apesar de não obter $E_0$, o \textbf{Cenário 1} dá uma informação importante. O algoritmo termina sempre quando $<\rho>$ fica próximo de $E_L$, mas não obtém $E_0$. Como pode ser visto na figura \ref{fig:execucoesSemente_EL_umPoucoAcima}, $<f>$ chega ao valor máximo 1 (gráfico da esquerda), mas o valor final médio para $\rho$ foi $E_{médio} = 0,387001$ (gráfico da direita). Então, se o algoritmo parar em $E_L$, significa que o autovalor mínimo é, com certeza, menor: $E_0 < E_L$. 
	
	\begin{figure}[htbp]
	\centering
  \begin{tabular}{@{}cc@{}}
	
		\includegraphics[width=.45\textwidth]{figs/resultados/variandoELSemente/T1_S-1445738835_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/variandoELSemente/T1_S-1445738835_rho.pdf}
  \end{tabular}
  \caption{Cenário 1. Execução para a semente 1445738835. $E_L$ um pouco acima de $E_0$ no \textit{fitness} $f_i = e^{-\beta(\rho_i - E_L)^2}$.}
	\label{fig:execucoesSemente_EL_umPoucoAcima}
	\end{figure}
	
	Com relação ao \textbf{Cenário 3} (\emph{muito} acima), novamente o algoritmo chegou ao $E_L$ em todas as execuções. Entretando, na última geração $|\nabla\rho|$ foi mais que trinta vezes maior comparado com o \textbf{Cenário 1} ($0,003 / 0,00009 \approx 33$). Retomando a condição de estacionaridade do Quociente de Rayleigh (equação \ref{eq:grad_rho_nulo}), isso significa que $<\rho>$ está mais distante de algum autovalor.

	\begin{figure}[htbp]
	\centering
  \begin{tabular}{@{}cc@{}}	
		\includegraphics[width=.45\textwidth]{figs/resultados/variandoELSemente/T3_S-1445738835_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/variandoELSemente/T3_S-1445738835_rho.pdf}
  \end{tabular}
  \caption{Execução para a semente 1445738835. $E_L$ muito acima de $E_0$ no \textit{fitness} $f_i = e^{-\beta(\rho_i - E_L)^2}$.}
	\label{fig:execucoesSemente_EL_umMuitoAcima}
	\end{figure}
		
	O valor de $\beta = 0,128788$, utilizado em todos os cenários anteriores, não foi adequado para os parâmetros do \textbf{Cenário 4}. Logo no início, tanto o \emph{<fitness>} quanto o maior \emph{fitness} foram praticamente zero.  Nesse regime não há como, a princípio, distinguir os indivíduos, pois todos possuem avaliação muito próxima. Veja no segundo gráfico da figura \ref{fig:execucoesSemente_EL_umMuitoAbaixo500} que $<\rho>$ rapidamente fica estagnado um pouco abaixo de 6. Especificamente, na geração 500, o Quociente de Rayleigh médio era $<\rho> = 5,651846$, que não corresponde a nenhum autovalor para uma matriz de Coope de ordem 10 (tabela \ref{tab:autovalores10a40}). Esse é um exemplo de \emph{underflow} do \emph{fitness}.
	
	\begin{figure}[htbp]
	\centering
  \begin{tabular}{@{}cc@{}}	
		\includegraphics[width=.45\textwidth]{figs/resultados/variandoELSemente/T4_S-1445738835_fitness.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/variandoELSemente/T4_S-1445738835_rho.pdf}
  \end{tabular}
  \caption{Execução para a semente 1445738835. $E_L$ muito abaixo de $E_0$ no \textit{fitness} $f_i = e^{-\beta(\rho_i - E_L)^2}$. Até geração 500.}
	\label{fig:execucoesSemente_EL_umMuitoAbaixo500}
	\end{figure}
		
	Entretanto, após várias gerações, houve convergência para o autovalor mínimo (figura \ref{fig:execucoesSemente_EL_umMuitoAbaixo40000}). Um pouco antes da geração 32.000 aconteceu um salto no \emph{fitness} (gráfico da esquerda), consequência de uma queda brusca do $<\rho>$ (gráfico da direita), que só pode ter sido possível com um salto na variabilidade genética na população, descontinuidade característica da Mutação. Apesar de o \emph{fitness} médio continuar pequeno após a mudança (<$f_i$> $< 0,025$), o \emph{crossover} foi capaz de atuar com a nova informação genética e criou variabilidade suficiente para chegar ao autovalor mínimo.
	
	Mesmo se não houvesse a descontinuidade, acredito que a queda de $<\rho>$ continuaria e haveria convergência para $<\rho>$ $\approx E_0$. Veja no segundo gráfico da figura \ref{fig:execucoesSemente_EL_umMuitoAbaixo40000} que entre o intervalo $0 \leq$ $<\rho>$ $\leq 30.000$ há uma queda lenta, porém sistemática, de $<\rho>$. Ou seja, apesar de pequeno, muito próximo de zero, o \emph{fitness} de cada indivíduo foi suficiente para permitir distinção na Seleção e reprodução no \emph{Crossover}. Portanto, se não ocorresse a queda brusca do $<\rho>$ em torno de $<\rho> = 32.000$, a diminuição seguiria lenta e o algoritmo chegaria ao autovalor mínimo.
	
	\begin{figure}[htbp]
	\centering
  \begin{tabular}{@{}cc@{}}	
		\includegraphics[width=.45\textwidth]{figs/resultados/variandoELSemente/T4_S-1445738835_fitness-extendido.pdf} &
    \includegraphics[width=.45\textwidth]{figs/resultados/variandoELSemente/T4_S-1445738835_rho_extendido.pdf}
  \end{tabular}
  \caption{Execução para a semente 1445738835. $E_L$ muito abaixo de $E_0$ no \textit{fitness} $f_i = e^{-\beta(\rho_i - E_L)^2}$. Geração entre 30.000 e 40.000.}
	\label{fig:execucoesSemente_EL_umMuitoAbaixo40000}
	\end{figure}
	
	Na tabela \ref{tab:VariandoELPraPrimeiraExecucao} há os valores desses testes. Como nas tabelas anteriores, os valores médios de $\rho$ e do \emph{fitness} (<$\rho$> e <\emph{fitness}>) foram calculados na geração final, ou seja, na população que atingiu algum dos critérios de parada. O <$\rho$> foi comparado com $E_0 = 0,386075$ para calcular o erro relativo (coluna Erro do <$\rho$> (\%)).

%\begin{landscape}
\begin{center}	
\begin{table}[htbp]
\caption{Variando $E_L$ para a execução da semente 1445738835. Os tipos de teste são: \textbf{cenário 1}: $E_L$ um pouco acima de $E_0$; \textbf{cenário 2}: $E_L$ um pouco abaixo de $E_0$; \textbf{cenário 3}: $E_L$ muito acima de $E_0$; \textbf{cenário 4}: $E_L$ muito abaixo de $E_0$.}
\label{tab:VariandoELPraPrimeiraExecucao}
\scalefont{0.7}
\centering
% Table generated by Excel2LaTeX from sheet 'Plan2'
\begin{tabular}{cccccccc}
\hline \hline
\textbf{Teste} &  \textbf{$E_L$} & \textbf{Geração final} & \textbf{<$\rho$>} & \textbf{$\sigma$} & \textbf{Erro do <$\rho$> (\%)} & \textbf{|$\nabla \rho$|} & \textbf{<\emph{Fitness}>} \\
\hline \hline
         1 &   0,387000 &     42.577 &     0,3870 &     0,0004 &      0,2\% &    0,00009 &   1,000000 \\
\hline
         2 &   0,385000 &    400.000 &    0,38615 &    0,00003 &     0,02\% &   0,000006 &   1,000000 \\
\hline
         3 &   5,000000 &      9.622 &       5,00 &       0,02 &     1195\% &      0,003 &   0,999966 \\
\hline
         4 &  -5,000000 &    400.000 &    0,38617 &    0,00003 &     0,03\% &     0,0003 &   0,023843 \\
\hline \hline
\end{tabular}   
\end{table}
\end{center}	
%%\end{landscape}
	
Em função dos resultados obtidos no cenário 4, analisei o \emph{fitness} de \cite{metodo2011}. O objetivo foi verificar como a variação dos parâmetros $\beta$ e $E_L$ alteram a forma de $f = \mathsf{e}^{-\beta(\rho - E_L)^2}$, e quais as consequências para o algoritmo genético. 
	
\begin{figure}[p]
	\centering
  \begin{tabular}{@{}cc@{}}
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-10_E-0_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-10_E-0_rho_extendido.pdf}   \\
		\includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-10_E-1_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-10_E-1_rho_extendido.pdf}   \\
		\includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-10_E-2_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-10_E-2_rho_extendido.pdf}   \\
		\includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-10_E-3_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-10_E-3_rho_extendido.pdf}   \\
		\includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-10_E-4_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-10_E-4_rho_extendido.pdf} \\
		\includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-10_E-5_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-10_E-5_rho_extendido.pdf}
  \end{tabular}
  \caption{Execuções para N = 10 com o \textit{fitness} $f_i = e^{-\beta(\rho_i - E_L)^2}$.}
	\label{fig:execucoes_N10_EL}
	\end{figure}
		
		\begin{figure}[p]
	\centering
  \begin{tabular}{@{}cc@{}}
		\includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-20_E-1_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-20_E-1_rho_extendido.pdf}   \\
		\includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-20_E-2_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-20_E-2_rho_extendido.pdf}   \\
		\includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-20_E-3_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-20_E-3_rho_extendido.pdf}   \\
		\includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-20_E-4_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-20_E-4_rho_extendido.pdf} \\
		\includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-20_E-5_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-20_E-5_rho_extendido.pdf}
  \end{tabular}
  \caption{Execuções para N = 20 com o \textit{fitness} $f_i = e^{-\beta(\rho_i - E_L)^2}$.}
	\label{fig:execucoes_N20_EL}
	\end{figure}
	
		\begin{figure}[p]
	\centering
  \begin{tabular}{@{}cc@{}}
		\includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-30_E-1_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-30_E-1_rho_extendido.pdf}   \\
		\includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-30_E-2_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-30_E-2_rho_extendido.pdf}   \\
		\includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-30_E-3_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-30_E-3_rho_extendido.pdf}   \\
		\includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-30_E-4_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-30_E-4_rho_extendido.pdf} \\
		\includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-30_E-5_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-30_E-5_rho_extendido.pdf}
  \end{tabular}
  \caption{Execuções para N = 30 com o \textit{fitness} $f_i = e^{-\beta(\rho_i - E_L)^2}$.}
	\label{fig:execucoes_N30_EL}
	\end{figure}
	
		\begin{figure}[p]
	\centering
  \begin{tabular}{@{}cc@{}}
		\includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-40_E-1_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-40_E-1_rho_extendido.pdf}   \\
		\includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-40_E-2_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-40_E-2_rho_extendido.pdf}   \\
		\includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-40_E-3_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-40_E-3_rho_extendido.pdf}   \\
		\includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-40_E-4_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-40_E-4_rho_extendido.pdf}		\\
		\includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-40_E-5_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/fitnessEL/N-40_E-5_rho_extendido.pdf}
  \end{tabular}
  \caption{Execuções para N = 40 com o \textit{fitness} $f_i = e^{-\beta(\rho_i - E_L)^2}$.}
	\label{fig:execucoes_N40_EL}
	\end{figure}
	
	%-------------------------------------------------
	
	\begin{figure}[p]
	\centering
  \begin{tabular}{@{}cc@{}}
    
		\includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T1E1_fitness.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T1E1_rho.pdf}   \\
		
		\includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T1E2_fitness.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T1E2_rho.pdf}   \\
		
		\includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T1E3_fitness.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T1E3_rho.pdf}   \\
		
		\includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T1E4_fitness.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T1E4_rho.pdf}   \\
		
		\includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T1E5_fitness.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T1E5_rho.pdf}		
  \end{tabular}
  \caption{Cenário 1. Várias execuções com o $E_L$ um pouco acima de $E_0$ no \textit{fitness} $f_i = e^{-\beta(\rho_i - E_L)^2}$. Semente 1445738835, N = 10.}
	\label{fig:variando_EL_pouco_acima}
	\end{figure}
	
\begin{figure}[p]
	\centering
  \begin{tabular}{@{}cc@{}}
			
		\includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T2E1_fitness.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T2E1_rho.pdf}   \\

		\includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T2E2_fitness.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T2E2_rho.pdf}   \\
		
		\includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T2E3_fitness.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T2E3_rho.pdf}   \\
		
		\includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T2E4_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T2E4_rho_extendido.pdf}   \\
		
		\includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T2E5_fitness.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T2E5_rho.pdf}

  \end{tabular}
  \caption{Execuções com o $E_L$ um pouco abaixo de $E_0$ no \textit{fitness} $f_i = e^{-\beta(\rho_i - E_L)^2}$. Semente 1445738835, N = 10.}
	\label{fig:variando_EL_pouco_abaixo}
	\end{figure}

\begin{figure}[p]
	\centering
  \begin{tabular}{@{}cc@{}}
   			
		\includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T3E1_fitness.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T3E1_rho.pdf}   \\

		\includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T3E2_fitness.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T3E2_rho.pdf}   \\
		
		\includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T3E3_fitness.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T3E3_rho.pdf}   \\
		
		\includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T3E4_fitness.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T3E4_rho.pdf}   \\
		
		\includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T3E5_fitness.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T3E5_rho.pdf}
		
  \end{tabular}
  \caption{Execuções com o $E_L$ muito acima de $E_0$ no \textit{fitness} $f_i = e^{-\beta(\rho_i - E_L)^2}$. Semente 1445738835, N = 10.}
	\label{fig:variando_EL_muito_acima}
	\end{figure}

\begin{figure}[p]
	\centering
  \begin{tabular}{@{}cc@{}}
 			
		\includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T4E1_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T4E1_rho_extendido.pdf}   \\

		\includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T4E2_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T4E2_rho_extendido.pdf}   \\
		
		\includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T4E3_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T4E3_rho_extendido.pdf}   \\
		
		\includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T4E4_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T4E4_rho_extendido.pdf}   \\
		
		\includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T4E5_fitness-extendido.pdf} &
    \includegraphics[width=.40\textwidth]{figs/resultados/variandoEL/T4E5_rho_extendido.pdf}
		
  \end{tabular}
  \caption{Execuções com o $E_L$ muito abaixo de $E_0$ no \textit{fitness} $f_i = e^{-\beta(\rho_i - E_L)^2}$. Semente 1445738835, N = 10.}
	\label{fig:variando_EL_muito_abaixo}
	\end{figure}
	
	\begin{landscape}
\begin{center}	
\begin{table}[htbp]
\caption{Cinco execuções para cada tipo de teste de variação de $E_L$ em torno de $E_0$ no fitness $f_i = e^{-\beta(\rho_i - E_L)^2}$.}
\label{tab:VariandoELCincoExecucoes}
\centering
% Table generated by Excel2LaTeX from sheet 'Plan2'
\begin{tabular}{ccccccccc}
\hline \hline
\textbf{Teste} & \textbf{Execução} & \textbf{Semente} & \textbf{Geração final} & \textbf{<$\rho$>} & \textbf{$\sigma$} & \textbf{Erro do <$\rho$> (\%)} & \textbf{|$\nabla \rho$|} & \textbf{<\emph{Fitness}>} \\
\hline \hline
         1 &          1 & 1448150274 &     47.945 &     0,3870 &     0,0005 &  0,00005\% &    0,00008 &   1,000000 \\
\hline
         1 &          2 & 1448150289 &     24.128 &     0,3870 &     0,0004 & -0,00004\% &    0,00008 &   1,000000 \\
\hline
         1 &          3 & 1448150298 &     40.795 &     0,3870 &     0,0003 & 0,000007\% &    0,00008 &   1,000000 \\
\hline
         1 &          4 & 1448150315 &     17.047 &     0,3870 &     0,0005 &  -0,0001\% &     0,0001 &   1,000000 \\
\hline
         1 &          5 & 1448150321 &     16.284 &     0,3870 &     0,0003 &  0,00002\% &    0,00008 &   1,000000 \\
\hline \hline
         2 &          1 & 1448150327 &    400.000 &    0,38616 &    0,00003 &     0,02\% &   0,000009 &   1,000000 \\
\hline
         2 &          2 & 1448150472 &    400.000 &    0,38613 &    0,00002 &     0,01\% &   0,000005 &   1,000000 \\
\hline
         2 &          3 & 1448150600 &    400.000 &    0,38613 &    0,00002 &     0,02\% &   0,000005 &   1,000000 \\
\hline
         2 &          4 & 1448150704 &    400.000 &    0,38624 &    0,00008 &     0,04\% &    0,00002 &   1,000000 \\
\hline
         2 &          5 & 1448150809 &    400.000 &    0,38624 &    0,00007 &     0,04\% &    0,00001 &   1,000000 \\
\hline \hline
         3 &          1 & 1448150912 &      8.074 &       5,00 &       0,05 &  0,00002\% &      0,007 &   0,999750 \\
\hline
         3 &          2 & 1448150914 &     14.604 &       5,00 &       0,03 & -0,000005\% &      0,009 &   0,999889 \\
\hline
         3 &          3 & 1448150918 &     41.659 &       5,00 &       0,02 & -0,00002\% &      0,003 &   0,999954 \\
\hline
         3 &          4 & 1448150929 &      9.775 &       5,00 &       0,03 & 0,000009\% &      0,006 &   0,999886 \\
\hline
         3 &          5 & 1448150932 &     12.637 &       5,00 &       0,03 & -0,0000006\% &      0,005 &   0,999904 \\
\hline \hline
         4 &          1 & 1448150935 &    400.000 &     0,3864 &     0,0001 &     0,07\% &      0,001 &   0,023837 \\
\hline
         4 &          2 & 1448151040 &    400.000 & 7,98166818 & 0,00000001 &     1967\% &        6,0 &   0,000000 \\
\hline
         4 &          3 & 1448151146 &    400.000 & 10,564998429558 & 0,000000000002 &     2637\% &        8,6 &   0,000000 \\
\hline
         4 &          4 & 1448151251 &    400.000 &    0,38613 &    0,00002 &     0,02\% &     0,0003 &   0,023844 \\
\hline
         4 &          5 & 1448151357 &    400.000 &    0,38614 &    0,00003 &     0,02\% &     0,0003 &   0,023844 \\
\hline \hline
\end{tabular}  
\end{table}
\end{center}	
\end{landscape}

%=========================================================
	\section{Análise do \emph{fitness} e equação empírica para $\beta$}\label{sec:eq_lambda}
%=========================================================
	
	Nos artigos \cite{metodo2004} e \cite{metodo2011} os autores dizem que o $\beta$ do \emph{fitness} deve ser escolhido cuidadosamente, mas não justificam com detalhes essa afirmação. Nesta sessão apresento uma análise do \emph{fitness} de \cite{metodo2011} e algumas justificativas para essa importância. Isso me permitiu definir uma equação empírica para o parâmetro $\beta$. Seu uso é restrito a matrizes de Coope--Sabo e ao \emph{fitness} do \cite{metodo2011}. Porém, com um pequeno ajuste, ela mostrou-se adequada também para o uso no \emph{fitness} de \cite{metodo2004}.
	
	A função de avaliação de \cite{metodo2011} é dada por
	
	\begin{equation}\label{eq:f_empirica}
		f_i = \mathsf{e}^{- \beta (\rho_i - 	E_L) ^2}.
	\end{equation}
	
	Na figura \ref{fig:f_simetrico} é possível verificar que $f$ é simétrica em torno de $E_L$, e possui máximo quando $\rho = E_L$. Alterar $E_L$ causa um deslocamento do máximo, mantendo a simetria (figura \ref{fig:f_deslocamento}). Essas propriedades são importantes, pois permitem que mudemos $E_L$, limite inferior para o menor autovalor, sem prejuízo do comportamento da função de avaliação.
	
	\begin{figure}[h]
		\centering
			\includegraphics[width=0.60\textwidth]{figs/resultados/precisaoFitness/f_simetrico.pdf}
		\caption{Simetria de $f_i = \mathsf{e}^{-\beta(\rho - E_L)^2}$. Nesse caso $E_L = 0$.}
		\label{fig:f_simetrico}
	\end{figure}
	
	\begin{figure}[h]
		\centering
			\includegraphics[width=0.60\textwidth]{figs/resultados/precisaoFitness/f_simetrico_outros.pdf}
		\caption{Deslocamento do máximo de $f_i = \mathsf{e}^{-\beta(\rho - E_L)^2}$}
		\label{fig:f_deslocamento}
	\end{figure}
	
	Na figura \ref{fig:f_efeito_lambda} \emph{f} é exibida, com $E_L = 0$, para cinco valores de $\beta$. No eixo das abscissas estão os valores de $\rho$, e nas ordenadas, os de $f$. Note que alterar $\beta$ mantém o centro da função, mas muda seu formato. Isso causa impacto na Seleção em dois pontos.
	
	\begin{figure}[h]
		\centering
			\includegraphics[width=1.0\textwidth]{figs/resultados/precisaoFitness/f_varios_lambdas.pdf}
		\caption{Efeito da mudança de $\beta$ em $f_i = \mathsf{e}^{-\beta(\rho - E_L)^2}$}
		\label{fig:f_efeito_lambda}
	\end{figure}
	
	 O primeiro é como isso pode influenciar a comparação dos indivíduos quando $\rho$ se aproxima de $E_L$. Note que o máximo de $f$ é muito mais acentuado para $\beta_f = 0,1 = 10^{-1}$ que para $\beta_a = 0,000001 = 10^{-6}$, fazendo com que o \emph{fitness} com $\beta_a$ pareça uma horizontal $f \approx 1$ no intervalo $\rho = [-20,20]$. Isso significa que um indivíduo ruim, com $\rho$ distante de $E_L = 0$, digamos $\rho = 10$, terá praticamente a mesma nota de um cromossomo com $\rho = 0,01$, próximo de $E_L$ e, portanto, de boa qualidade. Assim, $\beta$ deve ser escolhido para que a largura de $f$ seja pequena.
	
	Por outro lado, se a largura da função de avaliação for muito pequena, o mesmo tipo de problema acontecerá, mas para $f = 0$. Suponha que $\beta_f$ tenha sido escolhido, e que na população inicial alguns indivíduos possuam $\rho$ em torno de $\rho \approx 10$. Veja na figura \ref{fig:f_efeito_lambda} que todos eles terão nota $f = 0$, e certamente seriam preteridos em qualquer tipo de Seleção. Lembre-se que mesmo os piores indivíduos podem conter informação genética valiosa e, por isso, não devem ser sempre descartados \cite{Mitchell98}. Então, a escolha de $\beta$ deve garantir também que, desde a primeira geração, os piores indivíduos tenham \emph{fitness} maior que zero.

	Para as matrizes de Coope utilizadas neste trabalho, verifiquei uma regularidade na população inicial. Em geral o Quociente de Rayleigh médio $<\rho>$ ficava em torno dos autovalores centrais. Por exemplo, para matrizes com ordem N = 10, \mbox{$<\rho>$ $\approx E_4 = 8,6285$} (veja tabela \ref{tab:autovalores10a40}). Talvez a causa dessa regularidade esteja relacionada com a maneira como a matriz de Coope é definida (equação \ref{eq:MatrizCoope}). Com essa informação, pude construir uma equação empírica para $\beta$.

	A estratégia foi escolher um $\beta$ que faça o \emph{fitness} ser sempre muito pequeno, $f \approx 0 = 0,000001,$ na região dos autovalores centrais, e que dependesse apenas das características da matriz. No parâmetro $E_L$ usei $E_0$, assim, a função de avaliação fica limitada ao intervalo (0,1]. Isolando $\beta$ na equação \ref{eq:f_empirica} temos
	
	\begin{equation}
				\beta = - \frac{\ln f_i}{(\rho_i - E_L)^2},
	\end{equation}
	e incluindo os valores chega-se a
	
	\begin{equation}\label{eq:lambda_E-E0}
				\beta = - \frac{\ln(0,000001)}{(E_{central} - E_0)^2}.
	\end{equation}
	
	\begin{figure}
		\centering
			\includegraphics[width=0.60\textwidth]{figs/resultados/precisaoFitness/E-central_eE0_funcao_N.pdf}
		\caption{E central é linear}
		\label{fig:E-central_eE0_funcao_N}
	\end{figure}
	
	Os valores de $(E_{central} - E_0)$ foram calculados para matrizes de ordem N = 10 até N = 1.400, e estão na tabela \ref{tab:ValoresDeECentralE02}. Observe na figura \ref{fig:E-central_eE0_funcao_N} que $E_{central} - E_0 = f(\mathsf{N})$ é claramente linear. A regressão dá-nos
	
	\begin{equation}\label{eq:N_E-E0}
			E_{central} - E_0 = 1,00001\mathsf{N} - 1,6507.
	\end{equation}
	
	Utilizando a equação \ref{eq:N_E-E0} na \ref{eq:lambda_E-E0} cheguei finalmente a
	
	\begin{equation}\label{eq:lambda_N}
		\beta = - \frac{\ln(0,000001)}{(1,0001N - 1,6507)^2}.
	\end{equation}
		
	
	Inseri um termo 0,65 de ajuste para que a equação \ref{eq:lambda_N} também fosse adequada para o \emph{fitness} de \cite{metodo2004}:
	
	\begin{equation}\label{eq:lambda_N_ajustada}
		\beta = - 0,65 \frac{\ln(0,000001)}{(1,0001N - 1,6507)^2}
	\end{equation}
	
	O uso dessa equação permitiu automatizar completamente os testes para matrizes de Coope, além de facilitar a comparação entre os \emph{fitness} de \cite{metodo2004} e \cite{metodo2011}. Todas as execuções apresentadas nesta dissertação utilizaram a equação \ref{eq:lambda_N_ajustada}.
	
\begin{table}[htbp]
	\centering
	\caption{Valores de $(E_{central} - E_0)$.}
	\label{tab:ValoresDeECentralE02}
% Table generated by Excel2LaTeX from sheet 'dddd'
\begin{tabular}{rrrr}
\hline
         \textbf{N} & \textbf{E$_{0}$} &   \textbf{E$_{CENTRAL}$} & \textbf{E$_{CENTRAL}$} - \textbf{E$_{0}$} \\
\hline
        10 &   0,386075 &   8,628524 &   8,242449 \\

        20 &   0,341237 &  18,633845 &  18,292608 \\

        30 &   0,319737 &  28,635603 &  28,315866 \\

        40 &   0,306086 &  38,636479 &  38,330393 \\

        50 &   0,296280 &  48,637004 &  48,340724 \\

        60 &   0,288722 &  58,637353 &  58,348631 \\

        70 &   0,282625 &  68,637602 &  68,354977 \\

        80 &   0,277547 &  78,637789 &  78,360242 \\

        90 &   0,273215 &  88,637934 &  88,364719 \\

       100 &   0,269451 &  98,638050 &  98,368599 \\

       150 &   0,255873 & 148,638398 & 148,382525 \\

       200 &   0,247028 & 198,638572 & 198,391544 \\

       250 &   0,240570 & 248,638676 & 248,398106 \\

       300 &   0,235535 & 298,638746 & 298,403211 \\

       350 &   0,231435 & 348,638795 & 348,407360 \\

       400 &   0,227996 & 398,638833 & 398,410837 \\

       450 &   0,225044 & 448,638862 & 448,413818 \\

       500 &   0,222467 & 498,638885 & 498,416418 \\

       550 &   0,220184 & 548,638904 & 548,418720 \\

       600 &   0,218140 & 598,638919 & 598,420779 \\

       650 &   0,216293 & 648,638933 & 648,422640 \\

       700 &   0,214609 & 698,638944 & 698,424335 \\

       750 &   0,213065 & 748,638954 & 748,425889 \\

       800 &   0,211640 & 798,638963 & 798,427323 \\

       850 &   0,210318 & 848,638970 & 848,428652 \\

       900 &   0,209087 & 898,638977 & 898,429890 \\

       950 &   0,207935 & 948,638983 & 948,431048 \\

      1000 &   0,206853 & 998,638989 & 998,432136 \\

      1050 &   0,205835 & 1048,638994 & 1048,433159 \\

      1100 &   0,204873 & 1098,638998 & 1098,434125 \\

      1150 &   0,203962 & 1148,639002 & 1148,435040 \\

      1200 &   0,203098 & 1198,639006 & 1198,435908 \\

      1250 &   0,202275 & 1248,639010 & 1248,436735 \\

      1300 &   0,201491 & 1298,639013 & 1298,437522 \\

      1350 &   0,200742 & 1348,639016 & 1348,438274 \\

      1400 &   0,200025 & 1398,639019 & 1398,438994 \\
\hline
\end{tabular}  
\end{table}